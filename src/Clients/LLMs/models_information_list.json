{
  "$schema": "./models_information_spec.json",
  "gpt-4": {
    "max_tokens": 4096,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00003,
    "output_cost_per_token": 0.00006,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true
  },
  "gpt-4o": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000005,
    "output_cost_per_token": 0.000015,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-4o-mini": {
    "max_tokens": 16384,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "input_cost_per_token": 0.00000015,
    "output_cost_per_token": 0.00000060,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-4o-mini-2024-07-18": {
    "max_tokens": 16384,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "input_cost_per_token": 0.00000015,
    "output_cost_per_token": 0.00000060,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "o1-mini": {
    "max_tokens": 65536,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000012,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "o1-mini-2024-09-12": {
    "max_tokens": 65536,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000012,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "o1-preview": {
    "max_tokens": 32768,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "input_cost_per_token": 0.000015,
    "output_cost_per_token": 0.000060,

    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "o1-preview-2024-09-12": {
    "max_tokens": 32768,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "input_cost_per_token": 0.000015,
    "output_cost_per_token": 0.000060,

    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "chatgpt-4o-latest": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000005,
    "output_cost_per_token": 0.000015,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-4o-2024-05-13": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000005,
    "output_cost_per_token": 0.000015,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-4o-2024-08-06": {
    "max_tokens": 16384,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "input_cost_per_token": 0.0000025,
    "output_cost_per_token": 0.000010,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-4-turbo-preview": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-4-0314": {
    "max_tokens": 4096,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00003,
    "output_cost_per_token": 0.00006,
    "provider": "openai",
    "mode": "chat"
  },
  "gpt-4-0613": {
    "max_tokens": 4096,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00003,
    "output_cost_per_token": 0.00006,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true
  },
  "gpt-4-32k": {
    "max_tokens": 4096,
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00006,
    "output_cost_per_token": 0.00012,
    "provider": "openai",
    "mode": "chat"
  },
  "gpt-4-32k-0314": {
    "max_tokens": 4096,
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00006,
    "output_cost_per_token": 0.00012,
    "provider": "openai",
    "mode": "chat"
  },
  "gpt-4-32k-0613": {
    "max_tokens": 4096,
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00006,
    "output_cost_per_token": 0.00012,
    "provider": "openai",
    "mode": "chat"
  },
  "gpt-4-turbo": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-4-turbo-2024-04-09": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-4-1106-preview": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-4-0125-preview": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-4-vision-preview": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "openai",
    "mode": "chat"
  },
  "gpt-4-1106-vision-preview": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "openai",
    "mode": "chat"
  },
  "gpt-3.5-turbo": {
    "max_tokens": 4097,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.0000015,
    "output_cost_per_token": 0.000002,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true
  },
  "gpt-3.5-turbo-0301": {
    "max_tokens": 4097,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.0000015,
    "output_cost_per_token": 0.000002,
    "provider": "openai",
    "mode": "chat"
  },
  "gpt-3.5-turbo-0613": {
    "max_tokens": 4097,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.0000015,
    "output_cost_per_token": 0.000002,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true
  },
  "gpt-3.5-turbo-1106": {
    "max_tokens": 16385,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.0000010,
    "output_cost_per_token": 0.0000020,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-3.5-turbo-0125": {
    "max_tokens": 16385,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.0000005,
    "output_cost_per_token": 0.0000015,
    "provider": "openai",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "gpt-3.5-turbo-16k": {
    "max_tokens": 16385,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000004,
    "provider": "openai",
    "mode": "chat"
  },
  "gpt-3.5-turbo-16k-0613": {
    "max_tokens": 16385,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000004,
    "provider": "openai",
    "mode": "chat"
  },
  "text-embedding-3-large": {
    "max_tokens": 8191,
    "max_input_tokens": 8191,
    "output_vector_size": 3072,
    "input_cost_per_token": 0.00000013,
    "output_cost_per_token": 0.000000,
    "provider": "openai",
    "mode": "embedding"
  },
  "text-embedding-3-small": {
    "max_tokens": 8191,
    "max_input_tokens": 8191,
    "output_vector_size": 1536,
    "input_cost_per_token": 0.00000002,
    "output_cost_per_token": 0.000000,
    "provider": "openai",
    "mode": "embedding"
  },
  "text-embedding-ada-002": {
    "max_tokens": 8191,
    "max_input_tokens": 8191,
    "output_vector_size": 1536,
    "input_cost_per_token": 0.0000001,
    "output_cost_per_token": 0.000000,
    "provider": "openai",
    "mode": "embedding"
  },
  "text-embedding-ada-002-v2": {
    "max_tokens": 8191,
    "max_input_tokens": 8191,
    "input_cost_per_token": 0.0000001,
    "output_cost_per_token": 0.000000,
    "provider": "openai",
    "mode": "embedding"
  },
  "azure/o1-mini": {
    "max_tokens": 65536,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000012,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/o1-mini-2024-09-12": {
    "max_tokens": 65536,
    "max_input_tokens": 128000,
    "max_output_tokens": 65536,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000012,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/o1-preview": {
    "max_tokens": 32768,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "input_cost_per_token": 0.000015,
    "output_cost_per_token": 0.000060,

    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/o1-preview-2024-09-12": {
    "max_tokens": 32768,
    "max_input_tokens": 128000,
    "max_output_tokens": 32768,
    "input_cost_per_token": 0.000015,
    "output_cost_per_token": 0.000060,

    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-4o": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000005,
    "output_cost_per_token": 0.000015,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-4o-2024-08-06": {
    "max_tokens": 16384,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "input_cost_per_token": 0.00000275,
    "output_cost_per_token": 0.000011,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true

  },
  "azure/gpt-4o-2024-05-13": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000005,
    "output_cost_per_token": 0.000015,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/global-standard/gpt-4o-2024-08-06": {
    "max_tokens": 16384,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "input_cost_per_token": 0.0000025,
    "output_cost_per_token": 0.000010,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true

  },
  "azure/global-standard/gpt-4o-mini": {
    "max_tokens": 16384,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "input_cost_per_token": 0.00000015,
    "output_cost_per_token": 0.00000060,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true

  },
  "azure/gpt-4o-mini": {
    "max_tokens": 16384,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "input_cost_per_token": 0.000000165,
    "output_cost_per_token": 0.00000066,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-4o-mini-2024-07-18": {
    "max_tokens": 16384,
    "max_input_tokens": 128000,
    "max_output_tokens": 16384,
    "input_cost_per_token": 0.000000165,
    "output_cost_per_token": 0.00000066,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-4-turbo-2024-04-09": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-4-0125-preview": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-4-1106-preview": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-4-0613": {
    "max_tokens": 4096,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00003,
    "output_cost_per_token": 0.00006,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true
  },
  "azure/gpt-4-32k-0613": {
    "max_tokens": 4096,
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00006,
    "output_cost_per_token": 0.00012,
    "provider": "azure",
    "mode": "chat"
  },
  "azure/gpt-4-32k": {
    "max_tokens": 4096,
    "max_input_tokens": 32768,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00006,
    "output_cost_per_token": 0.00012,
    "provider": "azure",
    "mode": "chat"
  },
  "azure/gpt-4": {
    "max_tokens": 4096,
    "max_input_tokens": 8192,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00003,
    "output_cost_per_token": 0.00006,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true
  },
  "azure/gpt-4-turbo": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-4-turbo-vision-preview": {
    "max_tokens": 4096,
    "max_input_tokens": 128000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00001,
    "output_cost_per_token": 0.00003,
    "provider": "azure",
    "mode": "chat"

  },
  "azure/gpt-35-turbo-16k-0613": {
    "max_tokens": 4096,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000004,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true
  },
  "azure/gpt-35-turbo-1106": {
    "max_tokens": 4096,
    "max_input_tokens": 16384,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000001,
    "output_cost_per_token": 0.000002,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-35-turbo-0613": {
    "max_tokens": 4097,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.0000015,
    "output_cost_per_token": 0.000002,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-35-turbo-0301": {
    "max_tokens": 4097,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.0000002,
    "output_cost_per_token": 0.000002,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-35-turbo-0125": {
    "max_tokens": 4096,
    "max_input_tokens": 16384,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.0000005,
    "output_cost_per_token": 0.0000015,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true
  },
  "azure/gpt-35-turbo-16k": {
    "max_tokens": 4096,
    "max_input_tokens": 16385,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000004,
    "provider": "azure",
    "mode": "chat"
  },
  "azure/gpt-35-turbo": {
    "max_tokens": 4096,
    "max_input_tokens": 4097,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.0000005,
    "output_cost_per_token": 0.0000015,
    "provider": "azure",
    "mode": "chat",
    "supports_function_calling": true
  },
  "azure/ada": {
    "max_tokens": 8191,
    "max_input_tokens": 8191,
    "input_cost_per_token": 0.0000001,
    "output_cost_per_token": 0.000000,
    "provider": "azure",
    "mode": "embedding"
  },
  "azure/text-embedding-ada-002": {
    "max_tokens": 8191,
    "max_input_tokens": 8191,
    "input_cost_per_token": 0.0000001,
    "output_cost_per_token": 0.000000,
    "provider": "azure",
    "mode": "embedding"
  },
  "azure/text-embedding-3-large": {
    "max_tokens": 8191,
    "max_input_tokens": 8191,
    "input_cost_per_token": 0.00000013,
    "output_cost_per_token": 0.000000,
    "provider": "azure",
    "mode": "embedding"
  },
  "azure/text-embedding-3-small": {
    "max_tokens": 8191,
    "max_input_tokens": 8191,
    "input_cost_per_token": 0.00000002,
    "output_cost_per_token": 0.000000,
    "provider": "azure",
    "mode": "embedding"
  },
  "claude-3-haiku-20240307": {
    "max_tokens": 4096,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.00000025,
    "output_cost_per_token": 0.00000125,
    "provider": "anthropic",
    "mode": "chat",
    "supports_function_calling": true
  },
  "claude-3-5-haiku-20241022": {
    "max_tokens": 4096,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000001,
    "output_cost_per_token": 0.000005,
    "provider": "anthropic",
    "mode": "chat",
    "supports_function_calling": true
  },
  "claude-3-opus-20240229": {
    "max_tokens": 4096,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000015,
    "output_cost_per_token": 0.000075,
    "provider": "anthropic",
    "mode": "chat",
    "supports_function_calling": true
  },
  "claude-3-sonnet-20240229": {
    "max_tokens": 4096,
    "max_input_tokens": 200000,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000015,
    "provider": "anthropic",
    "mode": "chat",
    "supports_function_calling": true
  },
  "claude-3-5-sonnet-20240620": {
    "max_tokens": 8192,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000015,
    "provider": "anthropic",
    "mode": "chat",
    "supports_function_calling": true
  },
  "claude-3-5-sonnet-20241022": {
    "max_tokens": 8192,
    "max_input_tokens": 200000,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.000003,
    "output_cost_per_token": 0.000015,
    "provider": "anthropic",
    "mode": "chat",
    "supports_function_calling": true
  },
  "ollama/codegeex4": {
    "max_tokens": 32768,
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "chat",
    "supports_function_calling": false
  },
  "ollama/deepseek-coder-v2-instruct": {
    "max_tokens": 32768,
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "chat",
    "supports_function_calling": true
  },
  "ollama/deepseek-coder-v2-lite-instruct": {
    "max_tokens": 32768,
    "max_input_tokens": 32768,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "chat",
    "supports_function_calling": true
  },
  "ollama/deepseek-coder-v2-lite-base": {
    "max_tokens": 8192,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "chat",
    "supports_function_calling": true
  },
  "ollama/llama3": {
    "max_tokens": 8192,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "chat"
  },
  "ollama/llama3:8b": {
    "max_tokens": 8192,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "chat"
  },
  "ollama/llama3:70b": {
    "max_tokens": 8192,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "chat"
  },
  "ollama/llama3.1": {
    "max_tokens": 32768,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "chat",
    "supports_function_calling": true
  },
  "ollama/llama3.2": {
    "max_tokens": 32768,
    "max_input_tokens": 8192,
    "max_output_tokens": 8192,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "chat",
    "supports_function_calling": true
  },
  "ollama/codellama": {
    "max_tokens": 4096,
    "max_input_tokens": 4096,
    "max_output_tokens": 4096,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "chat"
  },
  "ollama/nomic-embed-text": {
    "max_tokens": 2048,
    "max_input_tokens": 2048,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "embedding",
    "embedding_dimensions": 512
  },
  "ollama/mxbai-embed-large": {
    "max_tokens": 4096,
    "max_input_tokens": 2048,
    "input_cost_per_token": 0.0,
    "output_cost_per_token": 0.0,
    "provider": "ollama",
    "mode": "embedding",
    "embedding_dimensions": 1024
  }
}